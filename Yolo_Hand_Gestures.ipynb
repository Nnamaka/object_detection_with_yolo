{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo_Hand_Gestures.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOlMmem8Pz32uL8rHZ1iZgX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nnamaka/object_detection_with_yolo/blob/main/Yolo_Hand_Gestures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hand Gesture Reccognition with YOLOv5\n"
      ],
      "metadata": {
        "id": "jWD-aUT0SNLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is a run-through of the major steps to perform a complete training pipeline for a custom object detection YOLO model using colab. "
      ],
      "metadata": {
        "id": "B83tcrLpShuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wrote a blog tutorial describing details of the procedure for training a Yolov5 model on your custom dataset. \n",
        "Check it out here--------"
      ],
      "metadata": {
        "id": "vAGJwk_2UWQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic steps are:\n",
        "\n",
        "* Install Yolo and its Requirments\n",
        "* Annotate dataset and serve if from Roboflow\n",
        "* Train Yolo for custom detections\n",
        "* Infer the new trainded model weights"
      ],
      "metadata": {
        "id": "89NUOZqbS8q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PSjoQIkzVhyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-1: Install Yolo from its Repository"
      ],
      "metadata": {
        "id": "z7GFCpuzViFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output"
      ],
      "metadata": {
        "id": "P3MXC0DSWf-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU?"
      ],
      "metadata": {
        "id": "GLgycPF3XdKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "metadata": {
        "id": "hEKwa5InW1zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clone her"
      ],
      "metadata": {
        "id": "Le42gNnqXiEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone yolo5\n",
        "!git clone https://github.com/ultralytics/yolov5  \n"
      ],
      "metadata": {
        "id": "GdQsuZAXV9a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirments"
      ],
      "metadata": {
        "id": "uzfmlb_NXpRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "%pip install -q roboflow"
      ],
      "metadata": {
        "id": "F-azH6wRW77p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-2: Fetch Annotated Dataset from Roboflow"
      ],
      "metadata": {
        "id": "_TGOGhB1X0eH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my dataset of hand gestures, I took a few pictures with my mobile phone, sent them to my PC and used the <a href=\"https://github.com/tzutalin/labelImg\">labelImg</a> tool to label them. labelImg has the function to label Image datasets to the PascalVOC format and also the Yolo format.\n",
        "\n"
      ],
      "metadata": {
        "id": "AaJt-Pffs9-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I an option to also export my raw image dataset to Roboflow and label them there. But I chose to do it in LabelImg. "
      ],
      "metadata": {
        "id": "eps8Njwb8xIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After Labeling my dataset, I exported it to <a href=\"https://roboflow.com/\">Roboflow</a>. A Great platform that addresses major pre-processing requirments for image dataset."
      ],
      "metadata": {
        "id": "_E0YQ8CjtupV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "copy the code from Roboflow and paste it in the cell below"
      ],
      "metadata": {
        "id": "Ped7t2yovClI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# paste your api key in the variable below\n",
        "api_key = 'paste your api key here'"
      ],
      "metadata": {
        "id": "V4sd3PHH1-Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvhUuCgFwlTg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=api_key)\n",
        "project = rf.workspace(\"gestures-kejav\").project(\"hand_gestures-iwirp\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "pDV7w85au7br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-3: Train"
      ],
      "metadata": {
        "id": "4eayMXhAttrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 8 --epochs 150 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "u4jZhgw5SB4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-4: Evaluate trained model"
      ],
      "metadata": {
        "id": "-fmjjumVv0jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While training goes on, Performance metrics are logged(saved in 'runs' folder)\n",
        "You can choose to run the cell below first before begining/running the training cell. This will enable you to monitor the model performance while training."
      ],
      "metadata": {
        "id": "RoJLCvFjwL6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "PNkxXt7wvskd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-5: Inference with trained model"
      ],
      "metadata": {
        "id": "85wYahjWwjBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
      ],
      "metadata": {
        "id": "OmzvChwNwuql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us view the inference result"
      ],
      "metadata": {
        "id": "ebeWn8pRw4_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "#change your the extension variable to your image type\n",
        "extension = '.jpg'\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*' + extension):\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "BHcKuhUkw8Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-6: Final step. Download your trained model"
      ],
      "metadata": {
        "id": "yzFFiwtnxcVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your model is served!"
      ],
      "metadata": {
        "id": "ATAhhshg-jfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('./runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "JcqpwcDOxlSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-7: Conclusion"
      ],
      "metadata": {
        "id": "An-zJG-h0eGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What?\n",
        "YOLO is amazing!\n",
        "\n",
        "I noticed the model didn't do well in the 'ThumbsUp' hand-gesture prediction. The differents ways to solve that are:\n",
        "\n",
        "* Increase the images for 'ThumbsUp'\n",
        "* Run the training for Longer epochs\n",
        "* Augument the 'ThumbsUp' images eg different light exposure, contrast, bluring , cropping , rotaion etc. This will give the model enough variated data to look at and learn from."
      ],
      "metadata": {
        "id": "Noy0Fgsw0ijP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Yt85Udrv1kuC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}